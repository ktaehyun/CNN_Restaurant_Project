{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.7, epochs 10, batch 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 35s 853ms/step - loss: 2.8180 - accuracy: 0.4336\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 38s 874ms/step - loss: 0.9763 - accuracy: 0.5426\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 35s 842ms/step - loss: 0.8046 - accuracy: 0.6458\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 33s 826ms/step - loss: 0.6157 - accuracy: 0.7583\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 36s 812ms/step - loss: 0.5701 - accuracy: 0.7821\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 39s 919ms/step - loss: 0.4532 - accuracy: 0.8291\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 36s 826ms/step - loss: 0.4448 - accuracy: 0.8263\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 31s 751ms/step - loss: 0.4340 - accuracy: 0.8395\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 36s 820ms/step - loss: 0.3851 - accuracy: 0.8597\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 34s 873ms/step - loss: 0.3756 - accuracy: 0.8589\n",
      "12/12 [==============================] - 13s 118ms/step - loss: 0.4629 - accuracy: 0.8233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4629119336605072, 0.8232694864273071]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 7:3 학습과 테스트 데이터 분리\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(60)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(60)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.7, epochs 10, batch 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - 37s 451ms/step - loss: 2.1849 - accuracy: 0.4501\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 38s 500ms/step - loss: 0.8485 - accuracy: 0.6329\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 38s 477ms/step - loss: 0.6179 - accuracy: 0.7495\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 38s 449ms/step - loss: 0.4935 - accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 39s 487ms/step - loss: 0.4771 - accuracy: 0.8159\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 36s 465ms/step - loss: 0.3683 - accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 34s 376ms/step - loss: 0.3516 - accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 36s 466ms/step - loss: 0.3161 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 37s 450ms/step - loss: 0.2873 - accuracy: 0.8961\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 40s 467ms/step - loss: 0.2850 - accuracy: 0.8906\n",
      "23/23 [==============================] - 15s 70ms/step - loss: 0.1830 - accuracy: 0.9411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18301525712013245, 0.9410898089408875]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 7:3 학습과 테스트 데이터 분리\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(30)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(30)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.7, epochs 10, batch 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 38s 223ms/step - loss: 1.7689 - accuracy: 0.4702\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 43s 301ms/step - loss: 0.6868 - accuracy: 0.7078\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 42s 292ms/step - loss: 0.5570 - accuracy: 0.7805\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 44s 286ms/step - loss: 0.4816 - accuracy: 0.8148\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 43s 299ms/step - loss: 0.4529 - accuracy: 0.8214\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 42s 273ms/step - loss: 0.3127 - accuracy: 0.8859\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 41s 266ms/step - loss: 0.2722 - accuracy: 0.9026\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 45s 288ms/step - loss: 0.2263 - accuracy: 0.9196\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 43s 302ms/step - loss: 0.2243 - accuracy: 0.9153\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 45s 295ms/step - loss: 0.1639 - accuracy: 0.9430\n",
      "46/46 [==============================] - 16s 36ms/step - loss: 0.1079 - accuracy: 0.9676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1079087033867836, 0.9675993919372559]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 7:3 학습과 테스트 데이터 분리\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(15)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(15)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.7, epochs 10, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "159/159 [==============================] - 38s 170ms/step - loss: 1.2550 - accuracy: 0.5428\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 49s 241ms/step - loss: 0.5538 - accuracy: 0.7830\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 47s 231ms/step - loss: 0.4636 - accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 51s 243ms/step - loss: 0.3977 - accuracy: 0.8524\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 46s 224ms/step - loss: 0.4441 - accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 52s 246ms/step - loss: 0.2632 - accuracy: 0.9110\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 50s 251ms/step - loss: 0.2196 - accuracy: 0.9248\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 50s 247ms/step - loss: 0.1941 - accuracy: 0.9227\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 49s 227ms/step - loss: 0.1478 - accuracy: 0.9516\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 40s 172ms/step - loss: 0.1108 - accuracy: 0.9615\n",
      "68/68 [==============================] - 12s 25ms/step - loss: 0.0507 - accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05074391886591911, 0.9882179498672485]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 7:3 학습과 테스트 데이터 분리\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.7, epochs 10, batch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "317/317 [==============================] - 54s 122ms/step - loss: 1.2507 - accuracy: 0.4772\n",
      "Epoch 2/10\n",
      "317/317 [==============================] - 53s 131ms/step - loss: 0.7835 - accuracy: 0.6844\n",
      "Epoch 3/10\n",
      "317/317 [==============================] - 55s 137ms/step - loss: 0.6000 - accuracy: 0.7793\n",
      "Epoch 4/10\n",
      "317/317 [==============================] - 55s 136ms/step - loss: 0.5293 - accuracy: 0.7840\n",
      "Epoch 5/10\n",
      "317/317 [==============================] - 59s 131ms/step - loss: 0.4707 - accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "317/317 [==============================] - 54s 135ms/step - loss: 0.3353 - accuracy: 0.8747\n",
      "Epoch 7/10\n",
      "317/317 [==============================] - 56s 139ms/step - loss: 0.3335 - accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "317/317 [==============================] - 56s 140ms/step - loss: 0.2343 - accuracy: 0.9131\n",
      "Epoch 9/10\n",
      "317/317 [==============================] - 52s 123ms/step - loss: 0.1824 - accuracy: 0.9352\n",
      "Epoch 10/10\n",
      "317/317 [==============================] - 61s 157ms/step - loss: 0.1886 - accuracy: 0.9339\n",
      "136/136 [==============================] - 15s 16ms/step - loss: 0.3111 - accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31106728315353394, 0.8821796774864197]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 7:3 학습과 테스트 데이터 분리\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(5)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(5)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.6, epochs 10, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "136/136 [==============================] - 37s 163ms/step - loss: 1.3079 - accuracy: 0.5320\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 34s 166ms/step - loss: 0.6397 - accuracy: 0.7565\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 42s 227ms/step - loss: 0.4892 - accuracy: 0.8172\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 34s 163ms/step - loss: 0.4729 - accuracy: 0.8325\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 42s 226ms/step - loss: 0.3420 - accuracy: 0.8616\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 41s 224ms/step - loss: 0.2976 - accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 42s 230ms/step - loss: 0.2794 - accuracy: 0.8959\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 33s 160ms/step - loss: 0.2265 - accuracy: 0.9172\n",
      "Epoch 9/10\n",
      "136/136 [==============================] - 42s 226ms/step - loss: 0.1635 - accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "136/136 [==============================] - 34s 166ms/step - loss: 0.1170 - accuracy: 0.9580\n",
      "91/91 [==============================] - 14s 25ms/step - loss: 0.1641 - accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16414760053157806, 0.935982346534729]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 3:2 학습과 테스트 데이터 분리\n",
    "train_size = int(0.6 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.8, epochs 10, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 44s 160ms/step - loss: 1.2122 - accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 49s 211ms/step - loss: 0.5725 - accuracy: 0.7908\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 43s 159ms/step - loss: 0.5176 - accuracy: 0.8219\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 52s 226ms/step - loss: 0.3796 - accuracy: 0.8566\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 49s 209ms/step - loss: 0.2866 - accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 52s 211ms/step - loss: 0.2170 - accuracy: 0.9260\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 42s 161ms/step - loss: 0.1711 - accuracy: 0.9394\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 50s 217ms/step - loss: 0.1506 - accuracy: 0.9482\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 40s 162ms/step - loss: 0.1109 - accuracy: 0.9587\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 41s 162ms/step - loss: 0.1496 - accuracy: 0.9403\n",
      "46/46 [==============================] - 12s 25ms/step - loss: 0.0482 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04817769303917885, 0.9889624714851379]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 4:1 학습과 테스트 데이터 분리\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 10)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.8, epochs 30, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "181/181 [==============================] - 45s 180ms/step - loss: 1.2122 - accuracy: 0.5529s - l - ETA: 0s - loss: 1.2177 - accuracy: \n",
      "Epoch 2/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.5725 - accuracy: 0.7908\n",
      "Epoch 3/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.5176 - accuracy: 0.8219\n",
      "Epoch 4/30\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.3796 - accuracy: 0.8566\n",
      "Epoch 5/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.2866 - accuracy: 0.8929\n",
      "Epoch 6/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.2170 - accuracy: 0.9260\n",
      "Epoch 7/30\n",
      "181/181 [==============================] - 46s 181ms/step - loss: 0.1711 - accuracy: 0.9394\n",
      "Epoch 8/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.1506 - accuracy: 0.9482\n",
      "Epoch 9/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.1109 - accuracy: 0.9587\n",
      "Epoch 10/30\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.1496 - accuracy: 0.9403\n",
      "Epoch 11/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.1109 - accuracy: 0.9615\n",
      "Epoch 12/30\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.0709 - accuracy: 0.9773\n",
      "Epoch 13/30\n",
      "181/181 [==============================] - 44s 175ms/step - loss: 0.0705 - accuracy: 0.9674\n",
      "Epoch 14/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.1031 - accuracy: 0.9676\n",
      "Epoch 15/30\n",
      "181/181 [==============================] - 43s 172ms/step - loss: 0.0802 - accuracy: 0.9724\n",
      "Epoch 16/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 17/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 18/30\n",
      "181/181 [==============================] - 48s 193ms/step - loss: 0.0563 - accuracy: 0.9823\n",
      "Epoch 19/30\n",
      "181/181 [==============================] - 50s 199ms/step - loss: 0.0534 - accuracy: 0.9826\n",
      "Epoch 20/30\n",
      "181/181 [==============================] - 50s 200ms/step - loss: 0.0735 - accuracy: 0.9755\n",
      "Epoch 21/30\n",
      "181/181 [==============================] - 49s 199ms/step - loss: 0.0313 - accuracy: 0.9905\n",
      "Epoch 22/30\n",
      "181/181 [==============================] - 51s 208ms/step - loss: 0.0866 - accuracy: 0.9727\n",
      "Epoch 23/30\n",
      "181/181 [==============================] - 50s 201ms/step - loss: 0.0286 - accuracy: 0.9906\n",
      "Epoch 24/30\n",
      "181/181 [==============================] - 50s 200ms/step - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 25/30\n",
      "181/181 [==============================] - 50s 201ms/step - loss: 0.1323 - accuracy: 0.9664\n",
      "Epoch 26/30\n",
      "181/181 [==============================] - 49s 198ms/step - loss: 0.0445 - accuracy: 0.9822\n",
      "Epoch 27/30\n",
      "181/181 [==============================] - 45s 175ms/step - loss: 0.0307 - accuracy: 0.9854\n",
      "Epoch 28/30\n",
      "181/181 [==============================] - 44s 172ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 29/30\n",
      "181/181 [==============================] - 41s 158ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 30/30\n",
      "181/181 [==============================] - 47s 200ms/step - loss: 0.0734 - accuracy: 0.9797\n",
      "46/46 [==============================] - 14s 23ms/step - loss: 0.0208 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020764268934726715, 0.9911699891090393]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 4:1 학습과 테스트 데이터 분리\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 30)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# train_size 0.8, epochs 29, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/29\n",
      "181/181 [==============================] - 47s 185ms/step - loss: 1.2122 - accuracy: 0.5529\n",
      "Epoch 2/29\n",
      "181/181 [==============================] - 45s 178ms/step - loss: 0.5725 - accuracy: 0.7908\n",
      "Epoch 3/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.5176 - accuracy: 0.8219 15s - loss: 0.5811 - accuracy: - ETA: 14s - ETA: 5s - loss: 0.5329 \n",
      "Epoch 4/29\n",
      "181/181 [==============================] - 45s 178ms/step - loss: 0.3796 - accuracy: 0.8566\n",
      "Epoch 5/29\n",
      "181/181 [==============================] - 45s 178ms/step - loss: 0.2866 - accuracy: 0.8929\n",
      "Epoch 6/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.2170 - accuracy: 0.9260\n",
      "Epoch 7/29\n",
      "181/181 [==============================] - 45s 175ms/step - loss: 0.1711 - accuracy: 0.9394\n",
      "Epoch 8/29\n",
      "181/181 [==============================] - 46s 180ms/step - loss: 0.1506 - accuracy: 0.9482 26s - loss: 0.1402 - accuracy - ETA: 25s - loss: 0.\n",
      "Epoch 9/29\n",
      "181/181 [==============================] - 45s 174ms/step - loss: 0.1109 - accuracy: 0.9587\n",
      "Epoch 10/29\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.1496 - accuracy: 0.9403\n",
      "Epoch 11/29\n",
      "181/181 [==============================] - 45s 176ms/step - loss: 0.1109 - accuracy: 0.9615\n",
      "Epoch 12/29\n",
      "181/181 [==============================] - 46s 180ms/step - loss: 0.0709 - accuracy: 0.9773s - loss: 0.0735 \n",
      "Epoch 13/29\n",
      "181/181 [==============================] - 45s 180ms/step - loss: 0.0705 - accuracy: 0.9674s - loss: 0.0711 - ac\n",
      "Epoch 14/29\n",
      "181/181 [==============================] - 45s 175ms/step - loss: 0.1031 - accuracy: 0.9676\n",
      "Epoch 15/29\n",
      "181/181 [==============================] - 46s 180ms/step - loss: 0.0802 - accuracy: 0.9724\n",
      "Epoch 16/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 17/29\n",
      "181/181 [==============================] - 45s 179ms/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 18/29\n",
      "181/181 [==============================] - 45s 176ms/step - loss: 0.0563 - accuracy: 0.9823\n",
      "Epoch 19/29\n",
      "181/181 [==============================] - 45s 176ms/step - loss: 0.0534 - accuracy: 0.9826\n",
      "Epoch 20/29\n",
      "181/181 [==============================] - 45s 176ms/step - loss: 0.0735 - accuracy: 0.9755\n",
      "Epoch 21/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.0313 - accuracy: 0.9905\n",
      "Epoch 22/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.0866 - accuracy: 0.9727\n",
      "Epoch 23/29\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.0286 - accuracy: 0.9906\n",
      "Epoch 24/29\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 25/29\n",
      "181/181 [==============================] - 45s 176ms/step - loss: 0.1323 - accuracy: 0.9664\n",
      "Epoch 26/29\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.0445 - accuracy: 0.9822\n",
      "Epoch 27/29\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.0307 - accuracy: 0.9854\n",
      "Epoch 28/29\n",
      "181/181 [==============================] - 44s 173ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 29/29\n",
      "181/181 [==============================] - 44s 175ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "46/46 [==============================] - 14s 27ms/step - loss: 0.0087 - accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008707712404429913, 0.9955849647521973]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 4:1 학습과 테스트 데이터 분리\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 29)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_size 0.8, epochs 58, batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 625)               15680625  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1878      \n",
      "=================================================================\n",
      "Total params: 15,775,751\n",
      "Trainable params: 15,775,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/58\n",
      "181/181 [==============================] - 41s 164ms/step - loss: 1.2122 - accuracy: 0.5529\n",
      "Epoch 2/58\n",
      "181/181 [==============================] - 40s 164ms/step - loss: 0.5725 - accuracy: 0.7908\n",
      "Epoch 3/58\n",
      "181/181 [==============================] - 40s 165ms/step - loss: 0.5176 - accuracy: 0.8219\n",
      "Epoch 4/58\n",
      "181/181 [==============================] - 42s 172ms/step - loss: 0.3796 - accuracy: 0.8566\n",
      "Epoch 5/58\n",
      "181/181 [==============================] - 41s 166ms/step - loss: 0.2866 - accuracy: 0.8929\n",
      "Epoch 6/58\n",
      "181/181 [==============================] - 41s 164ms/step - loss: 0.2170 - accuracy: 0.9260\n",
      "Epoch 7/58\n",
      "181/181 [==============================] - 42s 171ms/step - loss: 0.1711 - accuracy: 0.9394\n",
      "Epoch 8/58\n",
      "181/181 [==============================] - 42s 172ms/step - loss: 0.1506 - accuracy: 0.9482\n",
      "Epoch 9/58\n",
      "181/181 [==============================] - 43s 174ms/step - loss: 0.1109 - accuracy: 0.9587\n",
      "Epoch 10/58\n",
      "181/181 [==============================] - 44s 183ms/step - loss: 0.1496 - accuracy: 0.9403\n",
      "Epoch 11/58\n",
      "181/181 [==============================] - 68s 316ms/step - loss: 0.1109 - accuracy: 0.9615\n",
      "Epoch 12/58\n",
      "181/181 [==============================] - 55s 217ms/step - loss: 0.0709 - accuracy: 0.9773\n",
      "Epoch 13/58\n",
      "181/181 [==============================] - 53s 217ms/step - loss: 0.0705 - accuracy: 0.9674\n",
      "Epoch 14/58\n",
      "181/181 [==============================] - 51s 204ms/step - loss: 0.1031 - accuracy: 0.9676\n",
      "Epoch 15/58\n",
      "181/181 [==============================] - 49s 196ms/step - loss: 0.0802 - accuracy: 0.9724\n",
      "Epoch 16/58\n",
      "181/181 [==============================] - 51s 207ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 17/58\n",
      "181/181 [==============================] - 52s 209ms/step - loss: 0.0229 - accuracy: 0.9969s - loss: 0.0\n",
      "Epoch 18/58\n",
      "181/181 [==============================] - 47s 190ms/step - loss: 0.0563 - accuracy: 0.9823\n",
      "Epoch 19/58\n",
      "181/181 [==============================] - 48s 192ms/step - loss: 0.0534 - accuracy: 0.9826\n",
      "Epoch 20/58\n",
      "181/181 [==============================] - 46s 179ms/step - loss: 0.0735 - accuracy: 0.9755\n",
      "Epoch 21/58\n",
      "181/181 [==============================] - 50s 206ms/step - loss: 0.0313 - accuracy: 0.9905\n",
      "Epoch 22/58\n",
      "181/181 [==============================] - 56s 237ms/step - loss: 0.0866 - accuracy: 0.9727\n",
      "Epoch 23/58\n",
      "181/181 [==============================] - 58s 240ms/step - loss: 0.0286 - accuracy: 0.9906\n",
      "Epoch 24/58\n",
      "181/181 [==============================] - 58s 242ms/step - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 25/58\n",
      "181/181 [==============================] - 56s 226ms/step - loss: 0.1323 - accuracy: 0.9664\n",
      "Epoch 26/58\n",
      "181/181 [==============================] - 46s 181ms/step - loss: 0.0445 - accuracy: 0.9822\n",
      "Epoch 27/58\n",
      "181/181 [==============================] - 45s 178ms/step - loss: 0.0307 - accuracy: 0.9854\n",
      "Epoch 28/58\n",
      "181/181 [==============================] - 47s 189ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 29/58\n",
      "181/181 [==============================] - 47s 187ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 30/58\n",
      "181/181 [==============================] - 47s 187ms/step - loss: 0.0734 - accuracy: 0.9797\n",
      "Epoch 31/58\n",
      "181/181 [==============================] - 47s 186ms/step - loss: 0.0393 - accuracy: 0.9875\n",
      "Epoch 32/58\n",
      "181/181 [==============================] - 45s 180ms/step - loss: 0.0427 - accuracy: 0.9897\n",
      "Epoch 33/58\n",
      "181/181 [==============================] - 45s 179ms/step - loss: 0.0144 - accuracy: 0.9955\n",
      "Epoch 34/58\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.0435 - accuracy: 0.9870s - loss: 0.0435 - accuracy: 0.\n",
      "Epoch 35/58\n",
      "181/181 [==============================] - 44s 176ms/step - loss: 0.0494 - accuracy: 0.9852\n",
      "Epoch 36/58\n",
      "181/181 [==============================] - 47s 188ms/step - loss: 0.0432 - accuracy: 0.9883\n",
      "Epoch 37/58\n",
      "181/181 [==============================] - 52s 211ms/step - loss: 0.0180 - accuracy: 0.9937\n",
      "Epoch 38/58\n",
      "181/181 [==============================] - 53s 214ms/step - loss: 0.0303 - accuracy: 0.9922\n",
      "Epoch 39/58\n",
      "181/181 [==============================] - 47s 186ms/step - loss: 0.0069 - accuracy: 0.9973s - loss: 0.0068 - accu\n",
      "Epoch 40/58\n",
      "181/181 [==============================] - 45s 178ms/step - loss: 0.0214 - accuracy: 0.9910\n",
      "Epoch 41/58\n",
      "181/181 [==============================] - 50s 203ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "Epoch 42/58\n",
      "181/181 [==============================] - 52s 214ms/step - loss: 0.0105 - accuracy: 0.9986\n",
      "Epoch 43/58\n",
      "181/181 [==============================] - 52s 213ms/step - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 44/58\n",
      "181/181 [==============================] - 53s 215ms/step - loss: 0.0230 - accuracy: 0.9945\n",
      "Epoch 45/58\n",
      "181/181 [==============================] - 55s 227ms/step - loss: 0.0510 - accuracy: 0.9867\n",
      "Epoch 46/58\n",
      "181/181 [==============================] - 53s 214ms/step - loss: 0.0239 - accuracy: 0.9918\n",
      "Epoch 47/58\n",
      "181/181 [==============================] - 52s 208ms/step - loss: 0.0716 - accuracy: 0.9828\n",
      "Epoch 48/58\n",
      "181/181 [==============================] - 50s 194ms/step - loss: 0.0081 - accuracy: 0.9970\n",
      "Epoch 49/58\n",
      "181/181 [==============================] - 48s 193ms/step - loss: 0.0116 - accuracy: 0.9957\n",
      "Epoch 50/58\n",
      "181/181 [==============================] - 46s 178ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 51/58\n",
      "181/181 [==============================] - 44s 174ms/step - loss: 0.0307 - accuracy: 0.9940\n",
      "Epoch 52/58\n",
      "181/181 [==============================] - 45s 173ms/step - loss: 0.0337 - accuracy: 0.9913\n",
      "Epoch 53/58\n",
      "181/181 [==============================] - 45s 177ms/step - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 54/58\n",
      "181/181 [==============================] - 44s 175ms/step - loss: 0.0532 - accuracy: 0.9850\n",
      "Epoch 55/58\n",
      "181/181 [==============================] - 44s 171ms/step - loss: 0.0315 - accuracy: 0.9918\n",
      "Epoch 56/58\n",
      "181/181 [==============================] - 43s 171ms/step - loss: 0.0811 - accuracy: 0.9770\n",
      "Epoch 57/58\n",
      "181/181 [==============================] - 44s 171ms/step - loss: 0.0357 - accuracy: 0.9885\n",
      "Epoch 58/58\n",
      "181/181 [==============================] - 44s 175ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "46/46 [==============================] - 14s 26ms/step - loss: 0.0071 - accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007083272095769644, 0.9955849647521973]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "# 분류 대상 카테고리 선택하기\n",
    "restaurant_dir = \"C:/Users/You are mine ~/Desktop/빅데 데이터\"\n",
    "categories = [\"menupan\",\"restaurant_in\",\"restaurant_out\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "# 이미지 크기 지정 (128 X 128)\n",
    "# pixels = image_w * image_h * 3\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "all_image_paths = []\n",
    "all_onehot_labels = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    # 레이블 지정\n",
    "    label = [0 for i in range(nb_classes)] # one-hot 준비\n",
    "    label[idx] = 1 # one-hot 리스트 생성\n",
    "    image_dir = restaurant_dir + \"/\" + cat\n",
    "    # 각 폴더에 있는 모든 파일 이름에 대한 리스트 생성\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    for f in files:\n",
    "        all_image_paths.append(f)\n",
    "        all_onehot_labels.append(label)\n",
    "\n",
    "# tf.image 형태로 이미지 로딩\n",
    "# jpg를 디코딩하고 사이즈 조절과 정규화를 동시 진행\n",
    "# label 인자에 대한 처리는 하지 않고 단순히 받아서 그대로 리턴함\n",
    "def load_image_path_label(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_w,image_h])\n",
    "    image /= 255.0 # normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_onehot_labels))\n",
    "full_dataset = full_dataset.map(load_image_path_label)\n",
    "\n",
    "# 전체 데이터 갯수 계산\n",
    "DATASET_SIZE = len(all_image_paths)\n",
    "\n",
    "# 4:1 학습과 테스트 데이터 분리\n",
    "train_size = int(0.8 * DATASET_SIZE)\n",
    "test_size = DATASET_SIZE - train_size\n",
    "# 랜덤하게 shuffling\n",
    "full_dataset = full_dataset.shuffle(buffer_size = int(DATASET_SIZE*1.5))\n",
    "\n",
    "# 학습 데이터 생성\n",
    "train_ds = full_dataset.take(train_size)\n",
    "train_ds = train_ds.batch(10)\n",
    "\n",
    "# 나머지를 테스트용으로 사용\n",
    "test_ds = full_dataset.skip(train_size)\n",
    "test_ds = test_ds.batch(10)\n",
    "\n",
    "################################################### 모델 생성 ###################################################\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3, 3), input_shape=(image_w, image_h, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # default\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))      \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "          \n",
    "model.compile(optimizer = \"Adam\",\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.summary()\n",
    "\n",
    "model.fit(train_ds, epochs = 58)\n",
    "\n",
    "model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
